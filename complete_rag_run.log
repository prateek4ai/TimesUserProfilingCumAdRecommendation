ğŸš€ CTR Optimization Pipeline - Raw Data Sources
============================================================

ğŸ”„ Starting Data Ingestion Pipeline...
ğŸ“Š Generating User Event Stream...
âœ… Generated 1,000,000 events for 100,000 users
ğŸ·ï¸  Generating Item Metadata...
âœ… Generated metadata for 50,000 items
   - 7,564 sponsored items (15.1%)
ğŸŒ Adding Contextual Features...
âœ… Added contextual features

ğŸ” Data Validation:
Events shape: (1000000, 21)
Items shape: (50000, 16)
Memory usage: 118.8 MB
CTR: 0.200
Sponsored impression ratio: 0.151

ğŸ’¾ Raw data saved to outputs/
   - raw_events.parquet
   - raw_items.parquet

ğŸ¯ Next Steps:
1. Run Cell #2: Feature Engineering & Store
2. Run Cell #3: Baseline Model Training
3. Run Cell #4: RAG Pipeline Setup

ğŸ“‹ Sample Events:
shape: (5, 21)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ user_id â”† item_id â”† timestamp   â”† session_id â”† â€¦ â”† month â”† is_business â”† is_weekend â”† budget_uti â”‚
â”‚ ---     â”† ---     â”† ---         â”† ---        â”†   â”† ---   â”† _hours      â”† ---        â”† lization   â”‚
â”‚ i64     â”† i64     â”† datetime[ns â”† i64        â”†   â”† i8    â”† ---         â”† bool       â”† ---        â”‚
â”‚         â”†         â”† ]           â”†            â”†   â”†       â”† bool        â”†            â”† f64        â”‚
â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 15796   â”† 49263   â”† 2025-08-01  â”† 22142      â”† â€¦ â”† 8     â”† false       â”† false      â”† 0.48       â”‚
â”‚         â”†         â”† 00:00:00    â”†            â”†   â”†       â”†             â”†            â”†            â”‚
â”‚ 861     â”† 3214    â”† 2025-08-01  â”† 33601      â”† â€¦ â”† 8     â”† false       â”† false      â”† 0.48       â”‚
â”‚         â”†         â”† 00:01:00    â”†            â”†   â”†       â”†             â”†            â”†            â”‚
â”‚ 76821   â”† 35847   â”† 2025-08-01  â”† 2956       â”† â€¦ â”† 8     â”† false       â”† false      â”† 0.5        â”‚
â”‚         â”†         â”† 00:02:00    â”†            â”†   â”†       â”†             â”†            â”†            â”‚
â”‚ 54887   â”† 9037    â”† 2025-08-01  â”† 99024      â”† â€¦ â”† 8     â”† false       â”† false      â”† 0.48       â”‚
â”‚         â”†         â”† 00:03:00    â”†            â”†   â”†       â”†             â”†            â”†            â”‚
â”‚ 6266    â”† 30977   â”† 2025-08-01  â”† 54720      â”† â€¦ â”† 8     â”† false       â”† false      â”† 0.3        â”‚
â”‚         â”†         â”† 00:04:00    â”†            â”†   â”†       â”†             â”†            â”†            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“‹ Sample Items:
shape: (5, 16)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ item_id â”† price â”† margin_pct â”† brand_id â”† â€¦ â”† description  â”† margin_amoun â”† payout â”† is_out_of_s â”‚
â”‚ ---     â”† ---   â”† ---        â”† ---      â”†   â”† ---          â”† t            â”† ---    â”† tock        â”‚
â”‚ i64     â”† f64   â”† f64        â”† i64      â”†   â”† str          â”† ---          â”† f64    â”† ---         â”‚
â”‚         â”†       â”†            â”†          â”†   â”†              â”† f64          â”†        â”† i32         â”‚
â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 1       â”† 33.01 â”† 10.1       â”† 75       â”† â€¦ â”† High-quality â”† 3.33         â”† 1.451  â”† 0           â”‚
â”‚         â”†       â”†            â”†          â”†   â”† Fashion      â”†              â”†        â”†             â”‚
â”‚         â”†       â”†            â”†          â”†   â”† product wâ€¦   â”†              â”†        â”†             â”‚
â”‚ 2       â”† 17.49 â”† 25.3       â”† 204      â”† â€¦ â”† High-quality â”† 4.42         â”† 0.0    â”† 0           â”‚
â”‚         â”†       â”†            â”†          â”†   â”† Electronics  â”†              â”†        â”†             â”‚
â”‚         â”†       â”†            â”†          â”†   â”† produâ€¦       â”†              â”†        â”†             â”‚
â”‚ 3       â”† 38.39 â”† 46.6       â”† 332      â”† â€¦ â”† High-quality â”† 17.89        â”† 0.0    â”† 0           â”‚
â”‚         â”†       â”†            â”†          â”†   â”† Electronics  â”†              â”†        â”†             â”‚
â”‚         â”†       â”†            â”†          â”†   â”† produâ€¦       â”†              â”†        â”†             â”‚
â”‚ 4       â”† 92.11 â”† 47.9       â”† 319      â”† â€¦ â”† High-quality â”† 44.12        â”† 0.0    â”† 0           â”‚
â”‚         â”†       â”†            â”†          â”†   â”† Sports       â”†              â”†        â”†             â”‚
â”‚         â”†       â”†            â”†          â”†   â”† product wiâ€¦  â”†              â”†        â”†             â”‚
â”‚ 5       â”† 15.89 â”† 12.1       â”† 158      â”† â€¦ â”† High-quality â”† 1.92         â”† 0.0    â”† 0           â”‚
â”‚         â”†       â”†            â”†          â”†   â”† Sports       â”†              â”†        â”†             â”‚
â”‚         â”†       â”†            â”†          â”†   â”† product wiâ€¦  â”†              â”†        â”†             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸ”§ Feature Engineering & Store Pipeline
============================================================

ğŸ—ï¸ Assembling Feature Store...
ğŸ¯ Creating Sequence Features...
âœ… Created sequences for 99,990 users
â° Creating Temporal Aggregates...
âœ… User features: (99990, 15)
âœ… Item features: (50000, 9)
ğŸ”¤ Creating Content Embeddings...
âš ï¸ Embedding generation failed: 'Series' object has no attribute 'tolist'
âš ï¸ Creating dummy embeddings for compatibility...
ğŸ“Š Creating Exposure Buckets...
âœ… Created 10 exposure buckets with propensity weights
âœ… User feature store: (99990, 25)
âœ… Item feature store: (50000, 75)

ğŸ“ Preparing Training Data...
âœ… Sampled to 399,927 examples (CTR: 0.500)
âœ… Final training data: (399927, 40)

ğŸ’¾ Feature stores saved:
   - user_feature_store.parquet
   - item_feature_store.parquet
   - training_data.parquet

ğŸ“Š Total feature store memory: 175.0 MB

ğŸ¯ Next Steps:
1. Run Cell #3: Baseline Wide & Deep Model
2. Run Cell #4: Advanced Transformer Model (DIN/DIEN)
3. Run Cell #5: RAG Pipeline for Cold Items

ğŸ“‹ Sample Training Data:
shape: (5, 40)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ user_id â”† item_id â”† timestamp   â”† clicked â”† â€¦ â”† item_ctr â”† item_total_ â”† item_avg_d â”† item_uniqu â”‚
â”‚ ---     â”† ---     â”† ---         â”† ---     â”†   â”† ---      â”† impressions â”† well       â”† e_users    â”‚
â”‚ i64     â”† i64     â”† datetime[ns â”† i8      â”†   â”† f64      â”† ---         â”† ---        â”† ---        â”‚
â”‚         â”†         â”† ]           â”†         â”†   â”†          â”† u32         â”† f64        â”† u32        â”‚
â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 82387   â”† 23956   â”† 2025-08-01  â”† 1       â”† â€¦ â”† 0.272727 â”† 22          â”† 1860.95454 â”† 22         â”‚
â”‚         â”†         â”† 00:05:00    â”†         â”†   â”†          â”†             â”† 5          â”†            â”‚
â”‚ 41091   â”† 448     â”† 2025-08-01  â”† 1       â”† â€¦ â”† 0.3      â”† 20          â”† 2711.15    â”† 20         â”‚
â”‚         â”†         â”† 00:11:00    â”†         â”†   â”†          â”†             â”†            â”†            â”‚
â”‚ 64821   â”† 35995   â”† 2025-08-01  â”† 1       â”† â€¦ â”† 0.136364 â”† 22          â”† 1686.81818 â”† 22         â”‚
â”‚         â”†         â”† 00:13:00    â”†         â”†   â”†          â”†             â”† 2          â”†            â”‚
â”‚ 83105   â”† 42349   â”† 2025-08-01  â”† 1       â”† â€¦ â”† 0.230769 â”† 26          â”† 2169.30769 â”† 26         â”‚
â”‚         â”†         â”† 00:20:00    â”†         â”†   â”†          â”†             â”† 2          â”†            â”‚
â”‚ 53708   â”† 6342    â”† 2025-08-01  â”† 1       â”† â€¦ â”† 0.111111 â”† 18          â”† 1433.33333 â”† 18         â”‚
â”‚         â”†         â”† 00:21:00    â”†         â”†   â”†          â”†             â”† 3          â”†            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ Baseline Wide & Deep Model Training
============================================================
ğŸ“Š Data Overview:
  - Total samples: 399,927
  - Feature dimensions: 32
  - Label distribution: (array([0, 1], dtype=int8), array([200000, 199927]))

ğŸ¯ Stratified Split Results:
  - Train labels: (array([0, 1], dtype=int8), array([160000, 159941]))
  - Val labels: (array([0, 1], dtype=int8), array([40000, 39986]))

ğŸ“Š Model Architecture:
  - Categorical features: 7
  - Numerical features: 25
  - Total parameters: 28,912

ğŸš€ Training Wide & Deep Model...
Epoch 1/10:
  Train Loss: 5.9845
  Val Loss: 0.5276
  Val Metric (AUC/Acc): 0.8067
  Val LogLoss: 0.5277
Epoch 2/10:
  Train Loss: 5.0373
  Val Loss: 0.4648
  Val Metric (AUC/Acc): 0.8485
  Val LogLoss: 0.4651
Epoch 3/10:
  Train Loss: 4.6569
  Val Loss: 0.4437
  Val Metric (AUC/Acc): 0.8598
  Val LogLoss: 0.4442
Epoch 4/10:
  Train Loss: 4.5158
  Val Loss: 0.4356
  Val Metric (AUC/Acc): 0.8638
  Val LogLoss: 0.4362
Epoch 5/10:
  Train Loss: 4.4450
  Val Loss: 0.4307
  Val Metric (AUC/Acc): 0.8662
  Val LogLoss: 0.4311
Epoch 6/10:
  Train Loss: 4.3895
  Val Loss: 0.4265
  Val Metric (AUC/Acc): 0.8690
  Val LogLoss: 0.4271
Epoch 7/10:
  Train Loss: 4.3529
  Val Loss: 0.4218
  Val Metric (AUC/Acc): 0.8715
  Val LogLoss: 0.4221
Epoch 8/10:
  Train Loss: 4.3273
  Val Loss: 0.4183
  Val Metric (AUC/Acc): 0.8735
  Val LogLoss: 0.4187
Epoch 9/10:
  Train Loss: 4.3045
  Val Loss: 0.4192
  Val Metric (AUC/Acc): 0.8730
  Val LogLoss: 0.4195
Epoch 10/10:
  Train Loss: 4.2829
  Val Loss: 0.4174
  Val Metric (AUC/Acc): 0.8745
  Val LogLoss: 0.4179

âœ… Training Complete!
ğŸ“ˆ Best Validation Metric: 0.8745
ğŸ’¾ Model saved to: outputs/best_wide_deep_model.pt

ğŸ¯ Next Steps:
1. Run Cell #4: Advanced Transformer Model (DIN/DIEN)
2. Run Cell #5: RAG Pipeline for Cold Items
3. Run Cell #6: Agentic Re-ranker
ğŸ§  Advanced Transformer Model (DIN/DIEN) - Fixed
============================================================
ğŸ”„ Creating sequence dataset...
âŒ Error in sequence model training: too many values to unpack (expected 2)
âœ… Using baseline AUC: 0.8746

ğŸ¯ Next Steps:
1. Run Cell #5: RAG Pipeline for Cold Items
2. Run Cell #6: Agentic Re-ranker
3. Run Cell #7: End-to-End Evaluation
ğŸ” RAG Pipeline for Cold Items
============================================================
ğŸš€ Initializing RAG Pipeline...
âš ï¸  RAG Pipeline error: 'Series' object has no attribute 'tolist'
   Continuing without RAG...
ğŸ¯ Agentic Re-ranker - Multi-Objective Optimization
============================================================
ğŸ—ï¸ Initializing Integrated Recommendation Engine...

ğŸ”„ Generating recommendations for 5 test users...
âŒ Error generating recommendations for user 1001: DataFrame.sample() got an unexpected keyword argument 'random_state'
âŒ Error generating recommendations for user 1002: DataFrame.sample() got an unexpected keyword argument 'random_state'
âŒ Error generating recommendations for user 1003: DataFrame.sample() got an unexpected keyword argument 'random_state'
âŒ Error generating recommendations for user 1004: DataFrame.sample() got an unexpected keyword argument 'random_state'
âŒ Error generating recommendations for user 1005: DataFrame.sample() got an unexpected keyword argument 'random_state'

âœ… Agentic Re-ranker Complete!

ğŸ† Final System Performance Summary:
============================================================
ğŸ“Š Model Performance Stack:
  - Wide & Deep Baseline: 87.46% AUC
  - DIN Sequence Model: Architecture ready
  - RAG Cold Items: 20.55% avg CTR, 100% confidence
Traceback (most recent call last):
  File "/workspaces/TimesUserProfilingCumAdRecommendation/newnotebook.py", line 2191, in <module>
    print(f"  - Agentic Re-ranker: {agg_metrics['avg_ctr']*100:.2f}% avg CTR")
                                    ^^^^^^^^^^^
NameError: name 'agg_metrics' is not defined
