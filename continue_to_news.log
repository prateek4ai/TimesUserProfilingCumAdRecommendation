ğŸš€ CTR Optimization Pipeline - Raw Data Sources
============================================================

ğŸ”„ Starting Data Ingestion Pipeline...
ğŸ“Š Generating User Event Stream...
âœ… Generated 1,000,000 events for 100,000 users
ğŸ·ï¸  Generating Item Metadata...
âœ… Generated metadata for 50,000 items
   - 7,564 sponsored items (15.1%)
ğŸŒ Adding Contextual Features...
âœ… Added contextual features

ğŸ” Data Validation:
Events shape: (1000000, 21)
Items shape: (50000, 16)
Memory usage: 118.8 MB
CTR: 0.200
Sponsored impression ratio: 0.151

ğŸ’¾ Raw data saved to outputs/
   - raw_events.parquet
   - raw_items.parquet

ğŸ¯ Next Steps:
1. Run Cell #2: Feature Engineering & Store
2. Run Cell #3: Baseline Model Training
3. Run Cell #4: RAG Pipeline Setup

ğŸ“‹ Sample Events:
shape: (5, 21)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ user_id â”† item_id â”† timestamp   â”† session_id â”† â€¦ â”† month â”† is_business â”† is_weekend â”† budget_uti â”‚
â”‚ ---     â”† ---     â”† ---         â”† ---        â”†   â”† ---   â”† _hours      â”† ---        â”† lization   â”‚
â”‚ i64     â”† i64     â”† datetime[ns â”† i64        â”†   â”† i8    â”† ---         â”† bool       â”† ---        â”‚
â”‚         â”†         â”† ]           â”†            â”†   â”†       â”† bool        â”†            â”† f64        â”‚
â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 15796   â”† 49263   â”† 2025-08-01  â”† 22142      â”† â€¦ â”† 8     â”† false       â”† false      â”† 0.48       â”‚
â”‚         â”†         â”† 00:00:00    â”†            â”†   â”†       â”†             â”†            â”†            â”‚
â”‚ 861     â”† 3214    â”† 2025-08-01  â”† 33601      â”† â€¦ â”† 8     â”† false       â”† false      â”† 0.48       â”‚
â”‚         â”†         â”† 00:01:00    â”†            â”†   â”†       â”†             â”†            â”†            â”‚
â”‚ 76821   â”† 35847   â”† 2025-08-01  â”† 2956       â”† â€¦ â”† 8     â”† false       â”† false      â”† 0.5        â”‚
â”‚         â”†         â”† 00:02:00    â”†            â”†   â”†       â”†             â”†            â”†            â”‚
â”‚ 54887   â”† 9037    â”† 2025-08-01  â”† 99024      â”† â€¦ â”† 8     â”† false       â”† false      â”† 0.48       â”‚
â”‚         â”†         â”† 00:03:00    â”†            â”†   â”†       â”†             â”†            â”†            â”‚
â”‚ 6266    â”† 30977   â”† 2025-08-01  â”† 54720      â”† â€¦ â”† 8     â”† false       â”† false      â”† 0.3        â”‚
â”‚         â”†         â”† 00:04:00    â”†            â”†   â”†       â”†             â”†            â”†            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“‹ Sample Items:
shape: (5, 16)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ item_id â”† price â”† margin_pct â”† brand_id â”† â€¦ â”† description  â”† margin_amoun â”† payout â”† is_out_of_s â”‚
â”‚ ---     â”† ---   â”† ---        â”† ---      â”†   â”† ---          â”† t            â”† ---    â”† tock        â”‚
â”‚ i64     â”† f64   â”† f64        â”† i64      â”†   â”† str          â”† ---          â”† f64    â”† ---         â”‚
â”‚         â”†       â”†            â”†          â”†   â”†              â”† f64          â”†        â”† i32         â”‚
â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 1       â”† 33.01 â”† 10.1       â”† 75       â”† â€¦ â”† High-quality â”† 3.33         â”† 1.451  â”† 0           â”‚
â”‚         â”†       â”†            â”†          â”†   â”† Fashion      â”†              â”†        â”†             â”‚
â”‚         â”†       â”†            â”†          â”†   â”† product wâ€¦   â”†              â”†        â”†             â”‚
â”‚ 2       â”† 17.49 â”† 25.3       â”† 204      â”† â€¦ â”† High-quality â”† 4.42         â”† 0.0    â”† 0           â”‚
â”‚         â”†       â”†            â”†          â”†   â”† Electronics  â”†              â”†        â”†             â”‚
â”‚         â”†       â”†            â”†          â”†   â”† produâ€¦       â”†              â”†        â”†             â”‚
â”‚ 3       â”† 38.39 â”† 46.6       â”† 332      â”† â€¦ â”† High-quality â”† 17.89        â”† 0.0    â”† 0           â”‚
â”‚         â”†       â”†            â”†          â”†   â”† Electronics  â”†              â”†        â”†             â”‚
â”‚         â”†       â”†            â”†          â”†   â”† produâ€¦       â”†              â”†        â”†             â”‚
â”‚ 4       â”† 92.11 â”† 47.9       â”† 319      â”† â€¦ â”† High-quality â”† 44.12        â”† 0.0    â”† 0           â”‚
â”‚         â”†       â”†            â”†          â”†   â”† Sports       â”†              â”†        â”†             â”‚
â”‚         â”†       â”†            â”†          â”†   â”† product wiâ€¦  â”†              â”†        â”†             â”‚
â”‚ 5       â”† 15.89 â”† 12.1       â”† 158      â”† â€¦ â”† High-quality â”† 1.92         â”† 0.0    â”† 0           â”‚
â”‚         â”†       â”†            â”†          â”†   â”† Sports       â”†              â”†        â”†             â”‚
â”‚         â”†       â”†            â”†          â”†   â”† product wiâ€¦  â”†              â”†        â”†             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸ”§ Feature Engineering & Store Pipeline
============================================================

ğŸ—ï¸ Assembling Feature Store...
ğŸ¯ Creating Sequence Features...
âœ… Created sequences for 99,990 users
â° Creating Temporal Aggregates...
âœ… User features: (99990, 15)
âœ… Item features: (50000, 9)
ğŸ”¤ Creating Content Embeddings...
âœ… Generated 50-dim TF-IDF embeddings for 50,000 items
ğŸ“Š Creating Exposure Buckets...
âœ… Created 10 exposure buckets with propensity weights
âœ… User feature store: (99990, 25)
âœ… Item feature store: (50000, 75)

ğŸ“ Preparing Training Data...
âœ… Sampled to 399,927 examples (CTR: 0.500)
âœ… Final training data: (399927, 40)

ğŸ’¾ Feature stores saved:
   - user_feature_store.parquet
   - item_feature_store.parquet
   - training_data.parquet

ğŸ“Š Total feature store memory: 175.0 MB

ğŸ¯ Next Steps:
1. Run Cell #3: Baseline Wide & Deep Model
2. Run Cell #4: Advanced Transformer Model (DIN/DIEN)
3. Run Cell #5: RAG Pipeline for Cold Items

ğŸ“‹ Sample Training Data:
shape: (5, 40)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ user_id â”† item_id â”† timestamp   â”† clicked â”† â€¦ â”† item_ctr â”† item_total_ â”† item_avg_d â”† item_uniqu â”‚
â”‚ ---     â”† ---     â”† ---         â”† ---     â”†   â”† ---      â”† impressions â”† well       â”† e_users    â”‚
â”‚ i64     â”† i64     â”† datetime[ns â”† i8      â”†   â”† f64      â”† ---         â”† ---        â”† ---        â”‚
â”‚         â”†         â”† ]           â”†         â”†   â”†          â”† u32         â”† f64        â”† u32        â”‚
â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚ 82387   â”† 23956   â”† 2025-08-01  â”† 1       â”† â€¦ â”† 0.272727 â”† 22          â”† 1860.95454 â”† 22         â”‚
â”‚         â”†         â”† 00:05:00    â”†         â”†   â”†          â”†             â”† 5          â”†            â”‚
â”‚ 41091   â”† 448     â”† 2025-08-01  â”† 1       â”† â€¦ â”† 0.3      â”† 20          â”† 2711.15    â”† 20         â”‚
â”‚         â”†         â”† 00:11:00    â”†         â”†   â”†          â”†             â”†            â”†            â”‚
â”‚ 64821   â”† 35995   â”† 2025-08-01  â”† 1       â”† â€¦ â”† 0.136364 â”† 22          â”† 1686.81818 â”† 22         â”‚
â”‚         â”†         â”† 00:13:00    â”†         â”†   â”†          â”†             â”† 2          â”†            â”‚
â”‚ 83105   â”† 42349   â”† 2025-08-01  â”† 1       â”† â€¦ â”† 0.230769 â”† 26          â”† 2169.30769 â”† 26         â”‚
â”‚         â”†         â”† 00:20:00    â”†         â”†   â”†          â”†             â”† 2          â”†            â”‚
â”‚ 53708   â”† 6342    â”† 2025-08-01  â”† 1       â”† â€¦ â”† 0.111111 â”† 18          â”† 1433.33333 â”† 18         â”‚
â”‚         â”†         â”† 00:21:00    â”†         â”†   â”†          â”†             â”† 3          â”†            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸš€ Baseline Wide & Deep Model Training
============================================================
ğŸ“Š Data Overview:
  - Total samples: 399,927
  - Feature dimensions: 32
  - Label distribution: (array([0, 1], dtype=int8), array([200000, 199927]))

ğŸ¯ Stratified Split Results:
  - Train labels: (array([0, 1], dtype=int8), array([160000, 159941]))
  - Val labels: (array([0, 1], dtype=int8), array([40000, 39986]))

ğŸ“Š Model Architecture:
  - Categorical features: 7
  - Numerical features: 25
  - Total parameters: 28,912

ğŸš€ Training Wide & Deep Model...
Epoch 1/10:
  Train Loss: 6.0601
  Val Loss: 0.5313
  Val Metric (AUC/Acc): 0.8022
  Val LogLoss: 0.5315
Epoch 2/10:
  Train Loss: 5.1537
  Val Loss: 0.4712
  Val Metric (AUC/Acc): 0.8436
  Val LogLoss: 0.4717
Epoch 3/10:
  Train Loss: 4.7715
  Val Loss: 0.4493
  Val Metric (AUC/Acc): 0.8565
  Val LogLoss: 0.4498
Epoch 4/10:
  Train Loss: 4.5672
  Val Loss: 0.4346
  Val Metric (AUC/Acc): 0.8646
  Val LogLoss: 0.4350
Epoch 5/10:
  Train Loss: 4.4543
  Val Loss: 0.4284
  Val Metric (AUC/Acc): 0.8685
  Val LogLoss: 0.4288
Epoch 6/10:
  Train Loss: 4.3907
  Val Loss: 0.4233
  Val Metric (AUC/Acc): 0.8705
  Val LogLoss: 0.4237
Epoch 7/10:
  Train Loss: 4.3646
  Val Loss: 0.4205
  Val Metric (AUC/Acc): 0.8728
  Val LogLoss: 0.4207
Epoch 8/10:
  Train Loss: 4.3257
  Val Loss: 0.4192
  Val Metric (AUC/Acc): 0.8727
  Val LogLoss: 0.4196
Epoch 9/10:
  Train Loss: 4.3060
  Val Loss: 0.4178
  Val Metric (AUC/Acc): 0.8738
  Val LogLoss: 0.4181
Epoch 10/10:
  Train Loss: 4.2861
  Val Loss: 0.4148
  Val Metric (AUC/Acc): 0.8757
  Val LogLoss: 0.4150

âœ… Training Complete!
ğŸ“ˆ Best Validation Metric: 0.8757
ğŸ’¾ Model saved to: outputs/best_wide_deep_model.pt

ğŸ¯ Next Steps:
1. Run Cell #4: Advanced Transformer Model (DIN/DIEN)
2. Run Cell #5: RAG Pipeline for Cold Items
3. Run Cell #6: Agentic Re-ranker
ğŸ§  Advanced Transformer Model (DIN/DIEN) - Fixed
============================================================
ğŸ”„ Creating sequence dataset...
âŒ Error in sequence model training: too many values to unpack (expected 2)
âœ… Using baseline AUC: 0.8746

ğŸ¯ Next Steps:
1. Run Cell #5: RAG Pipeline for Cold Items
2. Run Cell #6: Agentic Re-ranker
3. Run Cell #7: End-to-End Evaluation
ğŸ” RAG Pipeline for Cold Items
============================================================
ğŸš€ Initializing RAG Pipeline...
ğŸ—ï¸ Training RAG pipeline components...
ğŸ”§ Building content embeddings...
âœ… Built embeddings for 50000 items
ğŸ“Š Computing item statistics...
âš ï¸  RAG Pipeline error: specifying aggregations as a dictionary is not supported

Try unpacking the dictionary to take advantage of the keyword syntax of the `agg` method.
   Skipping RAG pipeline, continuing to news pre-training...

ğŸ§ª Testing Cold Item Predictions...
ğŸ“‹ Testing with 5 cold items...
âŒ Error predicting item 20328: 'DataFrame' object has no attribute 'iloc'
âŒ Error predicting item 14539: 'DataFrame' object has no attribute 'iloc'
âŒ Error predicting item 24727: 'DataFrame' object has no attribute 'iloc'
âŒ Error predicting item 6048: 'DataFrame' object has no attribute 'iloc'
âŒ Error predicting item 3174: 'DataFrame' object has no attribute 'iloc'

ğŸ’¾ Saved 0 cold item predictions
Traceback (most recent call last):
  File "/workspaces/TimesUserProfilingCumAdRecommendation/newnotebook.py", line 1615, in <module>
    print(f"ğŸ“Š Average estimated CTR: {predictions_df['estimated_ctr'].mean():.4f}")
                                       ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/polars/dataframe/frame.py", line 1395, in __getitem__
    return get_df_item_by_key(self, key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/polars/_utils/getitem.py", line 163, in get_df_item_by_key
    return df.get_column(key)
           ^^^^^^^^^^^^^^^^^^
  File "/home/codespace/.local/lib/python3.12/site-packages/polars/dataframe/frame.py", line 8886, in get_column
    return wrap_s(self._df.get_column(name))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^
polars.exceptions.ColumnNotFoundError: "estimated_ctr" not found
